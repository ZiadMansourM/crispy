{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Final\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS: Final[int] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: tf.data.Dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(utils.DATA_DIR, 'dataset'),\n",
    "    shuffle=True,\n",
    "    image_size=(utils.IMG_HEIGHT, utils.IMG_WIDTH),\n",
    "    batch_size=utils.BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names: list[str] = dataset.class_names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Potato dataset batches:\n",
    "- 67 batches each 32 images.\n",
    "\"\"\"\n",
    "\n",
    "assert len(class_names) == 3\n",
    "assert len(dataset) == 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2152 // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2152 % 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Explore One of the Batches, Note:\n",
    "- press q to skip to the next image.\n",
    "\"\"\"\n",
    "\n",
    "# for images_batch, label_batch in dataset.take(1):\n",
    "#     assert images_batch.shape == (32, 256, 256, 3)\n",
    "#     assert images_batch[0].shape == (256, 256, 3)\n",
    "#     assert images_batch[0].numpy().astype(\"uint8\").max() == 255\n",
    "#     assert label_batch.shape == (32,)\n",
    "#     for image, label in zip(images_batch, label_batch):\n",
    "#         utils.show_image(\n",
    "#             image.numpy().astype(\"uint8\"), \n",
    "#             str(class_names[label])\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìù Start Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing\n",
    "- 80% \"1721 Images or 54 Batches\" of the data is used for training\n",
    "- 10% \"0215 Images or 06 Batches\" of the data is used for validation\n",
    "- 10% \"0216 Images or 08 Batches\" of the data is used for testing\n",
    "<hr/>\n",
    "-- total: 2152 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.cardinality().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_partitions(\n",
    "        dataset: tf.data.Dataset, \n",
    "        train_split: float=0.8, \n",
    "        validation_split: float=0.1,\n",
    "        test_split: float=0.1,\n",
    "        shuffle: bool=True\n",
    "    ) -> tuple[tf.data.Dataset, tf.data.Dataset, tf.data.Dataset]:\n",
    "    \"\"\"Split dataset into train, validation and test partitions.\"\"\"\n",
    "    DATASET_SIZE: Final[int] = dataset.cardinality().numpy()\n",
    "    \n",
    "    if shuffle:\n",
    "        import random\n",
    "        dataset = dataset.shuffle(\n",
    "            buffer_size=dataset.cardinality(), \n",
    "            seed=random.randint(0, 10_000)\n",
    "        )\n",
    "    \n",
    "    train_size = int(train_split * DATASET_SIZE)\n",
    "    val_size = int(validation_split * DATASET_SIZE)\n",
    "\n",
    "    \n",
    "    train_dataset = dataset.take(train_size)\n",
    "    validation_dataset = dataset.skip(train_size).take(val_size)\n",
    "    test_dataset = dataset.skip(train_size + val_size)\n",
    "\n",
    "    utils.log_to_file(\n",
    "        f\"Train size: {len(train_dataset)}, Validation size: {len(validation_dataset)}, Test size: {len(test_dataset)}\"\n",
    "    )\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, validation_dataset, test_dataset = get_dataset_partitions(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.cache().shuffle(\n",
    "    buffer_size=train_dataset.cardinality()\n",
    ").prefetch(\n",
    "    buffer_size=tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "validation_dataset = validation_dataset.cache().shuffle(\n",
    "    buffer_size=validation_dataset.cardinality()\n",
    ").prefetch(\n",
    "    buffer_size=tf.data.AUTOTUNE\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.cache().shuffle(\n",
    "    buffer_size=test_dataset.cardinality()\n",
    ").prefetch(\n",
    "    buffer_size=tf.data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "resize_rescale = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Resizing(utils.IMG_HEIGHT, utils.IMG_WIDTH),\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1.0/255)\n",
    "])\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (utils.BATCH_SIZE, utils.IMG_HEIGHT, utils.IMG_WIDTH, utils.CHANNELS)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    resize_rescale,\n",
    "    data_augmentation,\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.build(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.log_to_file(f\"Training model for {EPOCHS} epochs.\")\n",
    "import time\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_dataset\n",
    ")\n",
    "utils.log_to_file(f\"Training took {(time.time() - start_time):,.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_history = history.history['accuracy']\n",
    "val_accuracy_history = history.history['val_accuracy']\n",
    "loss_history = history.history['loss']\n",
    "val_loss_history = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(EPOCHS), accuracy_history, label='Training Accuracy')\n",
    "plt.plot(range(EPOCHS), val_accuracy_history, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(EPOCHS), loss_history, label='Training Loss')\n",
    "plt.plot(range(EPOCHS), val_loss_history, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "\n",
    "plt.savefig(os.path.join(utils.DATA_DIR, \"output\", \"accuracy.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.log_to_file(f\"Loss: {loss:,.4f}, Accuracy: {accuracy*100:,.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(utils.DATA_DIR, 'models', f\"potato_model_{EPOCHS}_{accuracy*100:.2f}.model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "for images_batch, label_batch in test_dataset:\n",
    "    for image, label in zip(images_batch, label_batch):\n",
    "        y_pred.append(np.argmax(model.predict(image[np.newaxis, ...])))\n",
    "        y_true.append(label.numpy())\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.log_to_file(f\"Number of wrong predictions: {(len(y_true) - np.trace(cm)):,} / {len(y_true):,}\")\n",
    "utils.log_to_file(f\"Accuracy: {(np.trace(cm) / len(y_true))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Early Blight', 'Late Blight', 'Healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "plt.savefig(os.path.join(utils.DATA_DIR, \"output\", \"confusion_matrix.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "for images_batch, label_batch in test_dataset:\n",
    "    wrong_predictions.extend(\n",
    "        (image.numpy().astype(\"uint8\"), label.numpy(), np.argmax(model.predict(image[np.newaxis, ...])))\n",
    "        for image, label in zip(images_batch, label_batch)\n",
    "        if np.argmax(model.predict(image[np.newaxis, ...])) != label.numpy()\n",
    "    )\n",
    "\n",
    "print(len(wrong_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show wrong predictions using utils.show_image\n",
    "# for image, true_label, predicted_label in wrong_predictions:\n",
    "#     utils.show_image(\n",
    "#         image, \n",
    "#         f\"True: {class_names[true_label]}, Predicted: {class_names[predicted_label]}\"\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
